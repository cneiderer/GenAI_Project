{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be30d77-6c5d-4b65-bca2-5446f0f628dd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6370855f-4090-4ea0-9b36-0d498c4e6556",
   "metadata": {},
   "source": [
    "Extracts image features from a directory of images using ResNet50,\n",
    "applies preprocessing compatible with ImageNet-trained models,\n",
    "and saves the features in compressed NumPy format (.npz)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b33fe-c0ec-4bb7-993e-51f5f3cd40eb",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac58e83b-73e3-4416-84e2-6d49d9d7ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : northeastern\n",
      "    active env location : /home/curtis/anaconda3/envs/northeastern\n",
      "            shell level : 2\n",
      "       user config file : /home/curtis/.condarc\n",
      " populated config files : /home/curtis/anaconda3/.condarc\n",
      "          conda version : 24.9.2\n",
      "    conda-build version : 24.9.0\n",
      "         python version : 3.12.7.final.0\n",
      "                 solver : libmamba (default)\n",
      "       virtual packages : __archspec=1=skylake\n",
      "                          __conda=24.9.2=0\n",
      "                          __glibc=2.39=0\n",
      "                          __linux=6.6.87.2=0\n",
      "                          __unix=0=0\n",
      "       base environment : /home/curtis/anaconda3  (writable)\n",
      "      conda av data dir : /home/curtis/anaconda3/etc/conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/linux-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "          package cache : /home/curtis/anaconda3/pkgs\n",
      "                          /home/curtis/.conda/pkgs\n",
      "       envs directories : /home/curtis/anaconda3/envs\n",
      "                          /home/curtis/.conda/envs\n",
      "               platform : linux-64\n",
      "             user-agent : conda/24.9.2 requests/2.32.3 CPython/3.12.7 Linux/6.6.87.2-microsoft-standard-WSL2 ubuntu/24.04.1 glibc/2.39 solver/libmamba conda-libmamba-solver/24.9.0 libmambapy/1.5.8 aau/0.4.4 c/. s/. e/.\n",
      "                UID:GID : 1000:1000\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confirm environment\n",
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "860c6b1b-bb74-46bf-8343-0fea5db09b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9058dcfc-50e0-47f3-9728-7c92bfebb49c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 16:14:50.263618: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-09 16:14:50.273192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752092090.289496   92687 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752092090.294728   92687 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752092090.305893   92687 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752092090.305915   92687 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752092090.305916   92687 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752092090.305917   92687 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-09 16:14:50.309055: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from vtt.config import IMAGENET_MEAN, IMAGENET_STD, IMAGE_SIZE\n",
    "from vtt.utils import detect_and_set_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45fd4d5c-045d-4b15-9f93-95b8b6427167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU devices found despite TensorFlow being built with CUDA. Using CPU.\n",
      "TensorFlow is configured to use: CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 16:14:52.356394: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "# Detect and set up GPU or use CPU\n",
    "device_used = detect_and_set_device()\n",
    "print(f\"TensorFlow is configured to use: {device_used}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6492abc-b633-4160-a04c-ec7826484d2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad483f36-000f-4ac0-aa65-35f092af7db0",
   "metadata": {},
   "source": [
    "## Process Images to Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9eb49e4-7873-4d83-bc1c-c9c0b3b446d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Preprocess a single image for ResNet50.\n",
    "\n",
    "    Args:\n",
    "        img_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Preprocessed image tensor with shape (1, 224, 224, 3).\n",
    "    \"\"\"\n",
    "    img = image.load_img(img_path, target_size=IMAGE_SIZE)\n",
    "    x = image.img_to_array(img) / 255.0\n",
    "    mean = np.array(IMAGENET_MEAN)\n",
    "    std = np.array(IMAGENET_STD)\n",
    "    x = (x - mean) / std\n",
    "    return np.expand_dims(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "160568e6-e45e-4fa4-96d1-ad056ddc7e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_directory(image_dir: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract ResNet50 features for all images in a directory.\n",
    "\n",
    "    Args:\n",
    "        image_dir (str): Path to directory containing images.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping from image filename to 2048-dim feature vector.\n",
    "    \"\"\"\n",
    "    print(f\"Extracting features from images in: {image_dir}\")\n",
    "\n",
    "    # Load ResNet50 model (pretrained on ImageNet)\n",
    "    base_model = ResNet50(weights=\"imagenet\")\n",
    "    feature_extractor = Model(\n",
    "        inputs=base_model.input,\n",
    "        outputs=base_model.get_layer(\"avg_pool\").output\n",
    "    )\n",
    "\n",
    "    features = {}\n",
    "    image_names = sorted(os.listdir(image_dir))\n",
    "\n",
    "    for img_name in tqdm(image_names, desc=\"Processing images\"):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        try:\n",
    "            img_tensor = preprocess_image(img_path)\n",
    "            feature = feature_extractor.predict(img_tensor, verbose=0)\n",
    "            features[img_name] = feature.squeeze()\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping {img_name} due to error: {e}\")\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c9f5805-5cd6-4ea2-8a8b-5ea52ed9f7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features(features: dict, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Save extracted features to a compressed .npz file.\n",
    "\n",
    "    Args:\n",
    "        features (dict): Dictionary of image features.\n",
    "        output_path (str): Path to save the .npz file.\n",
    "    \"\"\"\n",
    "    np.savez_compressed(output_path, **features)\n",
    "    print(f\"Saved features to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "778a088b-1c11-499c-9401-c085bb0fa15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from images in: ../../data/flickr8k_images/Images\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9616c7d4ca29417ab5aeff767a18fc33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing images:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved features to ../../data/flickr8k_features.npz\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "# images_dir = \"../../data/flickr8k_images/\"        # Full directory, only run on GPU\n",
    "images_dir = \"../../data/flickr8k_images/Images\"  # Subset of 10 images for proof-of-concept\n",
    "output_file = \"../../data/flickr8k_features.npz\"\n",
    "\n",
    "# Extract and save features\n",
    "features = extract_features_from_directory(images_dir)\n",
    "save_features(features, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d717912-eee6-4882-8246-55134364929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'10815824_2997e03d76.jpg': array([0.01160281, 0.        , 0.00789151, ..., 6.9319086 , 0.35592726,\n",
       "        0.        ], dtype=float32),\n",
       " '12830823_87d2654e31.jpg': array([0.2208504 , 0.0161181 , 0.24042735, ..., 6.5869427 , 0.        ,\n",
       "        0.        ], dtype=float32),\n",
       " '17273391_55cfc7d3d4.jpg': array([0.        , 0.38793966, 0.23146243, ..., 7.3355575 , 0.7991518 ,\n",
       "        0.        ], dtype=float32),\n",
       " '19212715_20476497a3.jpg': array([0.       , 0.       , 0.       , ..., 3.5574658, 0.       ,\n",
       "        0.       ], dtype=float32),\n",
       " '23445819_3a458716c1.jpg': array([0.00965334, 0.        , 0.50003254, ..., 3.7650876 , 0.5753617 ,\n",
       "        0.        ], dtype=float32),\n",
       " '27782020_4dab210360.jpg': array([0.02738906, 0.08970343, 0.28756386, ..., 7.796936  , 0.5479751 ,\n",
       "        0.        ], dtype=float32),\n",
       " '33108590_d685bfe51c.jpg': array([0.        , 0.01866938, 0.1363944 , ..., 7.4394717 , 0.53011143,\n",
       "        0.        ], dtype=float32),\n",
       " '35506150_cbdb630f4f.jpg': array([0.10631111, 0.06438331, 0.27659672, ..., 5.891857  , 0.18186927,\n",
       "        0.        ], dtype=float32),\n",
       " '3637013_c675de7705.jpg': array([0.        , 0.        , 0.25657845, ..., 6.9573    , 0.10602258,\n",
       "        0.        ], dtype=float32),\n",
       " '667626_18933d713e.jpg': array([0.05902706, 0.02418253, 0.03817456, ..., 3.6551108 , 0.14866176,\n",
       "        0.        ], dtype=float32)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load saved features\n",
    "loaded_features = np.load(output_file)\n",
    "features = {k: loaded_features[k] for k in loaded_features.files}\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271c4744-9810-44cb-9018-748e23e05efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef81755-2187-42c9-9ad1-16c44e0bfcb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa50a8-5330-44c7-a956-2cc89ed12e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "northeastern",
   "language": "python",
   "name": "northeastern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
